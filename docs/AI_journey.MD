https://zhuanlan.zhihu.com/p/665468388
**基础知识** 
**编程框架** 
**学习与复现现有的精典项目**
**推荐系统**
**LLM**

## 机器学习基础
下面这些主要是一些基础性的公式、简单的评估方法与模型的原理性的东西。如果要学习，最好是亲手写个代码
监督学习：线性回归、逻辑回归、支持向量机、决策树、随机森林、K 近邻、朴素贝叶斯等。
无监督学习：聚类、降维、密度估计等。
模型评估：交叉验证、偏差和方差、过拟合和欠拟合、性能指标（准确率、召回率、F1 分数等）。

## 深度学习基础
神经网络基础：前馈神经网络、反向传播算法、激活函数等。
卷积神经网络（CNN）：用于图像识别、对象检测等任务。
循环神经网络（RNN）：用于序列数据，如自然语言处理、时间序列分析等。


## 常见框架：TensorFlow、PyTorch、Keras 的基础知识。

### PyTorch 的基础结构和概念
张量（Tensor）：理解 PyTorch 中的基础数据结构张量，它类似于 NumPy 的数组。
自动微分（Autograd）：理解 PyTorch 的自动微分机制，如何利用它来自动计算梯度。
神经网络（nn.Module）：学习如何使用 PyTorch 的 nn.Module 来定义神经网络。这个玩意是所有自定义模型的基础
《PyTorch深度学习实践》完结合集 https://www.bilibili.com/video/BV1Y7411d7Ys/


## 学习与复现现有的精典项目
分类和回归竞赛
Titanic: Machine Learning from Disaster：一个入门级别的二元分类竞赛。
House Prices: Advanced Regression Techniques：一个房价预测的回归竞赛。
自然语言处理竞赛
Natural Language Processing with Disaster Tweets：通过推特预测灾害的发生。
计算机视觉竞赛
Digit Recognizer：基于 MNIST 数据集的手写数字识别竞赛。
时间序列预测竞赛
Web Traffic Time Series Forecasting：预测 Wikipedia 网页的未来访问量。

## LLM
### attention and Transformers
手写attention and transformer model

### Open source Models and frameworks

## Recommenders 
